[ Tue Oct 22 19:44:01 2024 ] using warm up, epoch: 5
[ Tue Oct 22 19:44:01 2024 ] Parameters:
{'work_dir': 'work_dir/001_new', 'model_saved_name': 'runs/001_new', 'config': './config/uav-cross-subjectv2/train.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_A_joint.npy', 'label_path': './data/test_A_label.npy'}, 'model': 'model.tegcn.Model', 'model_args': {'num_class': 155, 'num_point': 17, 'num_person': 2, 'graph': 'graph.uav.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 2, 'warm_up_epoch': 5}

[ Tue Oct 22 19:44:01 2024 ] Training epoch: 1
[ Tue Oct 22 19:47:49 2024 ] 	Mean training loss: 4.6484.
[ Tue Oct 22 19:47:49 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 19:47:49 2024 ] Eval epoch: 1
[ Tue Oct 22 19:48:05 2024 ] 	Mean test loss of 63 batches: 4.352896856883215.
[ Tue Oct 22 19:48:05 2024 ] 	Top1: 3.95%
[ Tue Oct 22 19:48:05 2024 ] 	Top5: 14.05%
[ Tue Oct 22 19:48:05 2024 ] Training epoch: 2
[ Tue Oct 22 19:51:51 2024 ] 	Mean training loss: 4.3582.
[ Tue Oct 22 19:51:51 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 19:51:51 2024 ] Eval epoch: 2
[ Tue Oct 22 19:52:07 2024 ] 	Mean test loss of 63 batches: 3.9586871692112515.
[ Tue Oct 22 19:52:07 2024 ] 	Top1: 6.75%
[ Tue Oct 22 19:52:07 2024 ] 	Top5: 24.55%
[ Tue Oct 22 19:52:07 2024 ] Training epoch: 3
[ Tue Oct 22 19:55:53 2024 ] 	Mean training loss: 3.8512.
[ Tue Oct 22 19:55:53 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 19:55:53 2024 ] Eval epoch: 3
[ Tue Oct 22 19:56:09 2024 ] 	Mean test loss of 63 batches: 3.1645507963876875.
[ Tue Oct 22 19:56:09 2024 ] 	Top1: 16.10%
[ Tue Oct 22 19:56:09 2024 ] 	Top5: 48.50%
[ Tue Oct 22 19:56:09 2024 ] Training epoch: 4
[ Tue Oct 22 19:59:57 2024 ] 	Mean training loss: 3.4435.
[ Tue Oct 22 19:59:57 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 19:59:57 2024 ] Eval epoch: 4
[ Tue Oct 22 20:00:13 2024 ] 	Mean test loss of 63 batches: 2.9685004495439076.
[ Tue Oct 22 20:00:13 2024 ] 	Top1: 22.05%
[ Tue Oct 22 20:00:13 2024 ] 	Top5: 55.05%
[ Tue Oct 22 20:00:13 2024 ] Training epoch: 5
[ Tue Oct 22 20:04:03 2024 ] 	Mean training loss: 3.1860.
[ Tue Oct 22 20:04:03 2024 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Oct 22 20:04:03 2024 ] Eval epoch: 5
[ Tue Oct 22 20:04:20 2024 ] 	Mean test loss of 63 batches: 2.515876153158763.
[ Tue Oct 22 20:04:20 2024 ] 	Top1: 29.65%
[ Tue Oct 22 20:04:20 2024 ] 	Top5: 68.25%
[ Tue Oct 22 20:04:20 2024 ] Training epoch: 6
[ Tue Oct 22 20:08:07 2024 ] 	Mean training loss: 2.9699.
[ Tue Oct 22 20:08:07 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:08:08 2024 ] Eval epoch: 6
[ Tue Oct 22 20:08:24 2024 ] 	Mean test loss of 63 batches: 2.4044875095761014.
[ Tue Oct 22 20:08:24 2024 ] 	Top1: 33.65%
[ Tue Oct 22 20:08:24 2024 ] 	Top5: 72.00%
[ Tue Oct 22 20:08:24 2024 ] Training epoch: 7
[ Tue Oct 22 20:12:12 2024 ] 	Mean training loss: 2.7941.
[ Tue Oct 22 20:12:12 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:12:12 2024 ] Eval epoch: 7
[ Tue Oct 22 20:12:28 2024 ] 	Mean test loss of 63 batches: 2.1122488559238493.
[ Tue Oct 22 20:12:28 2024 ] 	Top1: 39.40%
[ Tue Oct 22 20:12:28 2024 ] 	Top5: 78.40%
[ Tue Oct 22 20:12:28 2024 ] Training epoch: 8
[ Tue Oct 22 20:16:14 2024 ] 	Mean training loss: 2.6616.
[ Tue Oct 22 20:16:14 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 20:16:14 2024 ] Eval epoch: 8
[ Tue Oct 22 20:16:30 2024 ] 	Mean test loss of 63 batches: 2.271508326606145.
[ Tue Oct 22 20:16:30 2024 ] 	Top1: 36.75%
[ Tue Oct 22 20:16:30 2024 ] 	Top5: 72.45%
[ Tue Oct 22 20:16:30 2024 ] Training epoch: 9
[ Tue Oct 22 20:20:17 2024 ] 	Mean training loss: 2.5590.
[ Tue Oct 22 20:20:17 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:20:17 2024 ] Eval epoch: 9
[ Tue Oct 22 20:20:34 2024 ] 	Mean test loss of 63 batches: 4.338730163044399.
[ Tue Oct 22 20:20:34 2024 ] 	Top1: 13.50%
[ Tue Oct 22 20:20:34 2024 ] 	Top5: 36.20%
[ Tue Oct 22 20:20:34 2024 ] Training epoch: 10
[ Tue Oct 22 20:24:20 2024 ] 	Mean training loss: 2.4506.
[ Tue Oct 22 20:24:20 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 20:24:20 2024 ] Eval epoch: 10
[ Tue Oct 22 20:24:36 2024 ] 	Mean test loss of 63 batches: 4.541716696724059.
[ Tue Oct 22 20:24:36 2024 ] 	Top1: 16.65%
[ Tue Oct 22 20:24:36 2024 ] 	Top5: 38.50%
[ Tue Oct 22 20:24:36 2024 ] Training epoch: 11
[ Tue Oct 22 20:28:23 2024 ] 	Mean training loss: 2.3649.
[ Tue Oct 22 20:28:23 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:28:23 2024 ] Eval epoch: 11
[ Tue Oct 22 20:28:41 2024 ] 	Mean test loss of 63 batches: 4.166004029531328.
[ Tue Oct 22 20:28:41 2024 ] 	Top1: 18.80%
[ Tue Oct 22 20:28:41 2024 ] 	Top5: 42.15%
[ Tue Oct 22 20:28:41 2024 ] Training epoch: 12
[ Tue Oct 22 20:32:28 2024 ] 	Mean training loss: 2.3109.
[ Tue Oct 22 20:32:28 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:32:28 2024 ] Eval epoch: 12
[ Tue Oct 22 20:32:45 2024 ] 	Mean test loss of 63 batches: 1.8523062136438158.
[ Tue Oct 22 20:32:45 2024 ] 	Top1: 48.00%
[ Tue Oct 22 20:32:45 2024 ] 	Top5: 82.95%
[ Tue Oct 22 20:32:45 2024 ] Training epoch: 13
[ Tue Oct 22 20:36:31 2024 ] 	Mean training loss: 2.2490.
[ Tue Oct 22 20:36:31 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:36:31 2024 ] Eval epoch: 13
[ Tue Oct 22 20:36:48 2024 ] 	Mean test loss of 63 batches: 1.6763705999132186.
[ Tue Oct 22 20:36:48 2024 ] 	Top1: 51.55%
[ Tue Oct 22 20:36:48 2024 ] 	Top5: 84.85%
[ Tue Oct 22 20:36:48 2024 ] Training epoch: 14
[ Tue Oct 22 20:40:35 2024 ] 	Mean training loss: 2.1739.
[ Tue Oct 22 20:40:35 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:40:35 2024 ] Eval epoch: 14
[ Tue Oct 22 20:40:52 2024 ] 	Mean test loss of 63 batches: 1.7070243632982647.
[ Tue Oct 22 20:40:52 2024 ] 	Top1: 50.60%
[ Tue Oct 22 20:40:52 2024 ] 	Top5: 84.85%
[ Tue Oct 22 20:40:52 2024 ] Training epoch: 15
[ Tue Oct 22 20:44:38 2024 ] 	Mean training loss: 2.1238.
[ Tue Oct 22 20:44:38 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 20:44:38 2024 ] Eval epoch: 15
[ Tue Oct 22 20:44:54 2024 ] 	Mean test loss of 63 batches: 1.6819811898564536.
[ Tue Oct 22 20:44:55 2024 ] 	Top1: 49.40%
[ Tue Oct 22 20:44:55 2024 ] 	Top5: 83.90%
[ Tue Oct 22 20:44:55 2024 ] Training epoch: 16
[ Tue Oct 22 20:48:41 2024 ] 	Mean training loss: 2.0760.
[ Tue Oct 22 20:48:41 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 20:48:41 2024 ] Eval epoch: 16
[ Tue Oct 22 20:48:58 2024 ] 	Mean test loss of 63 batches: 1.5611162743871174.
[ Tue Oct 22 20:48:58 2024 ] 	Top1: 53.50%
[ Tue Oct 22 20:48:58 2024 ] 	Top5: 86.85%
[ Tue Oct 22 20:48:58 2024 ] Training epoch: 17
[ Tue Oct 22 20:52:44 2024 ] 	Mean training loss: 2.0252.
[ Tue Oct 22 20:52:44 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 20:52:44 2024 ] Eval epoch: 17
[ Tue Oct 22 20:53:01 2024 ] 	Mean test loss of 63 batches: 1.6108982146732391.
[ Tue Oct 22 20:53:01 2024 ] 	Top1: 54.85%
[ Tue Oct 22 20:53:01 2024 ] 	Top5: 87.30%
[ Tue Oct 22 20:53:01 2024 ] Training epoch: 18
[ Tue Oct 22 20:56:47 2024 ] 	Mean training loss: 1.9845.
[ Tue Oct 22 20:56:47 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 20:56:47 2024 ] Eval epoch: 18
[ Tue Oct 22 20:57:04 2024 ] 	Mean test loss of 63 batches: 1.7427680464017958.
[ Tue Oct 22 20:57:04 2024 ] 	Top1: 51.55%
[ Tue Oct 22 20:57:04 2024 ] 	Top5: 84.85%
[ Tue Oct 22 20:57:04 2024 ] Training epoch: 19
[ Tue Oct 22 21:00:49 2024 ] 	Mean training loss: 1.9601.
[ Tue Oct 22 21:00:49 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 21:00:49 2024 ] Eval epoch: 19
[ Tue Oct 22 21:01:05 2024 ] 	Mean test loss of 63 batches: 1.54869321319792.
[ Tue Oct 22 21:01:05 2024 ] 	Top1: 53.25%
[ Tue Oct 22 21:01:05 2024 ] 	Top5: 88.05%
[ Tue Oct 22 21:01:05 2024 ] Training epoch: 20
[ Tue Oct 22 21:04:51 2024 ] 	Mean training loss: 1.9129.
[ Tue Oct 22 21:04:51 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 21:04:51 2024 ] Eval epoch: 20
[ Tue Oct 22 21:05:10 2024 ] 	Mean test loss of 63 batches: 1.6627648879611303.
[ Tue Oct 22 21:05:10 2024 ] 	Top1: 50.75%
[ Tue Oct 22 21:05:10 2024 ] 	Top5: 86.85%
[ Tue Oct 22 21:05:10 2024 ] Training epoch: 21
[ Tue Oct 22 21:08:57 2024 ] 	Mean training loss: 1.8879.
[ Tue Oct 22 21:08:57 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:08:57 2024 ] Eval epoch: 21
[ Tue Oct 22 21:09:13 2024 ] 	Mean test loss of 63 batches: 1.454870492219925.
[ Tue Oct 22 21:09:13 2024 ] 	Top1: 57.50%
[ Tue Oct 22 21:09:13 2024 ] 	Top5: 88.80%
[ Tue Oct 22 21:09:13 2024 ] Training epoch: 22
[ Tue Oct 22 21:12:59 2024 ] 	Mean training loss: 1.8577.
[ Tue Oct 22 21:12:59 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 21:12:59 2024 ] Eval epoch: 22
[ Tue Oct 22 21:13:14 2024 ] 	Mean test loss of 63 batches: 1.5290743145677779.
[ Tue Oct 22 21:13:15 2024 ] 	Top1: 55.55%
[ Tue Oct 22 21:13:15 2024 ] 	Top5: 87.55%
[ Tue Oct 22 21:13:15 2024 ] Training epoch: 23
[ Tue Oct 22 21:17:01 2024 ] 	Mean training loss: 1.8293.
[ Tue Oct 22 21:17:01 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:17:01 2024 ] Eval epoch: 23
[ Tue Oct 22 21:17:19 2024 ] 	Mean test loss of 63 batches: 1.57339427490083.
[ Tue Oct 22 21:17:19 2024 ] 	Top1: 55.10%
[ Tue Oct 22 21:17:19 2024 ] 	Top5: 87.40%
[ Tue Oct 22 21:17:19 2024 ] Training epoch: 24
[ Tue Oct 22 21:21:06 2024 ] 	Mean training loss: 1.8083.
[ Tue Oct 22 21:21:06 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:21:06 2024 ] Eval epoch: 24
[ Tue Oct 22 21:21:22 2024 ] 	Mean test loss of 63 batches: 1.5752207868629031.
[ Tue Oct 22 21:21:22 2024 ] 	Top1: 54.80%
[ Tue Oct 22 21:21:22 2024 ] 	Top5: 86.20%
[ Tue Oct 22 21:21:22 2024 ] Training epoch: 25
[ Tue Oct 22 21:25:08 2024 ] 	Mean training loss: 1.7716.
[ Tue Oct 22 21:25:08 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 21:25:08 2024 ] Eval epoch: 25
[ Tue Oct 22 21:25:24 2024 ] 	Mean test loss of 63 batches: 1.4899241356622606.
[ Tue Oct 22 21:25:24 2024 ] 	Top1: 55.85%
[ Tue Oct 22 21:25:24 2024 ] 	Top5: 87.80%
[ Tue Oct 22 21:25:24 2024 ] Training epoch: 26
[ Tue Oct 22 21:29:11 2024 ] 	Mean training loss: 1.7586.
[ Tue Oct 22 21:29:11 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:29:11 2024 ] Eval epoch: 26
[ Tue Oct 22 21:29:28 2024 ] 	Mean test loss of 63 batches: 1.4074256462710244.
[ Tue Oct 22 21:29:28 2024 ] 	Top1: 59.00%
[ Tue Oct 22 21:29:28 2024 ] 	Top5: 88.75%
[ Tue Oct 22 21:29:28 2024 ] Training epoch: 27
[ Tue Oct 22 21:33:15 2024 ] 	Mean training loss: 1.7228.
[ Tue Oct 22 21:33:15 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:33:15 2024 ] Eval epoch: 27
[ Tue Oct 22 21:33:31 2024 ] 	Mean test loss of 63 batches: 1.5690182797492496.
[ Tue Oct 22 21:33:31 2024 ] 	Top1: 54.50%
[ Tue Oct 22 21:33:31 2024 ] 	Top5: 86.45%
[ Tue Oct 22 21:33:31 2024 ] Training epoch: 28
[ Tue Oct 22 21:37:18 2024 ] 	Mean training loss: 1.7055.
[ Tue Oct 22 21:37:18 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:37:18 2024 ] Eval epoch: 28
[ Tue Oct 22 21:37:34 2024 ] 	Mean test loss of 63 batches: 1.4077397471382505.
[ Tue Oct 22 21:37:34 2024 ] 	Top1: 58.45%
[ Tue Oct 22 21:37:34 2024 ] 	Top5: 89.20%
[ Tue Oct 22 21:37:34 2024 ] Training epoch: 29
[ Tue Oct 22 21:41:21 2024 ] 	Mean training loss: 1.6744.
[ Tue Oct 22 21:41:21 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 21:41:21 2024 ] Eval epoch: 29
[ Tue Oct 22 21:41:40 2024 ] 	Mean test loss of 63 batches: 1.5264623221896945.
[ Tue Oct 22 21:41:40 2024 ] 	Top1: 57.40%
[ Tue Oct 22 21:41:40 2024 ] 	Top5: 87.65%
[ Tue Oct 22 21:41:40 2024 ] Training epoch: 30
[ Tue Oct 22 21:45:26 2024 ] 	Mean training loss: 1.6481.
[ Tue Oct 22 21:45:26 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 21:45:26 2024 ] Eval epoch: 30
[ Tue Oct 22 21:45:42 2024 ] 	Mean test loss of 63 batches: 1.4752458504268102.
[ Tue Oct 22 21:45:42 2024 ] 	Top1: 57.50%
[ Tue Oct 22 21:45:42 2024 ] 	Top5: 88.35%
[ Tue Oct 22 21:45:42 2024 ] Training epoch: 31
[ Tue Oct 22 21:49:28 2024 ] 	Mean training loss: 1.2778.
[ Tue Oct 22 21:49:28 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 21:49:28 2024 ] Eval epoch: 31
[ Tue Oct 22 21:49:44 2024 ] 	Mean test loss of 63 batches: 1.0413827550789667.
[ Tue Oct 22 21:49:44 2024 ] 	Top1: 68.05%
[ Tue Oct 22 21:49:44 2024 ] 	Top5: 93.35%
[ Tue Oct 22 21:49:44 2024 ] Training epoch: 32
[ Tue Oct 22 21:53:29 2024 ] 	Mean training loss: 1.1678.
[ Tue Oct 22 21:53:29 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 21:53:30 2024 ] Eval epoch: 32
[ Tue Oct 22 21:53:46 2024 ] 	Mean test loss of 63 batches: 1.0444164190973555.
[ Tue Oct 22 21:53:46 2024 ] 	Top1: 67.95%
[ Tue Oct 22 21:53:46 2024 ] 	Top5: 93.30%
[ Tue Oct 22 21:53:46 2024 ] Training epoch: 33
[ Tue Oct 22 21:57:35 2024 ] 	Mean training loss: 1.1185.
[ Tue Oct 22 21:57:35 2024 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Oct 22 21:57:35 2024 ] Eval epoch: 33
[ Tue Oct 22 21:57:52 2024 ] 	Mean test loss of 63 batches: 1.060643450608329.
[ Tue Oct 22 21:57:52 2024 ] 	Top1: 67.45%
[ Tue Oct 22 21:57:52 2024 ] 	Top5: 93.15%
[ Tue Oct 22 21:57:52 2024 ] Training epoch: 34
[ Tue Oct 22 22:01:38 2024 ] 	Mean training loss: 1.0884.
[ Tue Oct 22 22:01:38 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 22:01:38 2024 ] Eval epoch: 34
[ Tue Oct 22 22:01:54 2024 ] 	Mean test loss of 63 batches: 1.0425165111110324.
[ Tue Oct 22 22:01:54 2024 ] 	Top1: 68.20%
[ Tue Oct 22 22:01:54 2024 ] 	Top5: 93.50%
[ Tue Oct 22 22:01:54 2024 ] Training epoch: 35
[ Tue Oct 22 22:05:41 2024 ] 	Mean training loss: 1.0593.
[ Tue Oct 22 22:05:41 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:05:41 2024 ] Eval epoch: 35
[ Tue Oct 22 22:06:01 2024 ] 	Mean test loss of 63 batches: 1.0599375069141388.
[ Tue Oct 22 22:06:01 2024 ] 	Top1: 68.55%
[ Tue Oct 22 22:06:01 2024 ] 	Top5: 93.15%
[ Tue Oct 22 22:06:01 2024 ] Training epoch: 36
[ Tue Oct 22 22:09:47 2024 ] 	Mean training loss: 1.0313.
[ Tue Oct 22 22:09:47 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:09:47 2024 ] Eval epoch: 36
[ Tue Oct 22 22:10:03 2024 ] 	Mean test loss of 63 batches: 1.063257611460156.
[ Tue Oct 22 22:10:03 2024 ] 	Top1: 68.10%
[ Tue Oct 22 22:10:03 2024 ] 	Top5: 93.45%
[ Tue Oct 22 22:10:03 2024 ] Training epoch: 37
[ Tue Oct 22 22:13:50 2024 ] 	Mean training loss: 0.9955.
[ Tue Oct 22 22:13:50 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:13:50 2024 ] Eval epoch: 37
[ Tue Oct 22 22:14:06 2024 ] 	Mean test loss of 63 batches: 1.0686217754606218.
[ Tue Oct 22 22:14:06 2024 ] 	Top1: 68.40%
[ Tue Oct 22 22:14:06 2024 ] 	Top5: 92.95%
[ Tue Oct 22 22:14:06 2024 ] Training epoch: 38
[ Tue Oct 22 22:17:52 2024 ] 	Mean training loss: 0.9716.
[ Tue Oct 22 22:17:52 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:17:52 2024 ] Eval epoch: 38
[ Tue Oct 22 22:18:08 2024 ] 	Mean test loss of 63 batches: 1.0832438894680567.
[ Tue Oct 22 22:18:08 2024 ] 	Top1: 68.10%
[ Tue Oct 22 22:18:08 2024 ] 	Top5: 93.05%
[ Tue Oct 22 22:18:08 2024 ] Training epoch: 39
[ Tue Oct 22 22:21:54 2024 ] 	Mean training loss: 0.9484.
[ Tue Oct 22 22:21:54 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:21:54 2024 ] Eval epoch: 39
[ Tue Oct 22 22:22:11 2024 ] 	Mean test loss of 63 batches: 1.0772500421319688.
[ Tue Oct 22 22:22:11 2024 ] 	Top1: 69.20%
[ Tue Oct 22 22:22:11 2024 ] 	Top5: 92.70%
[ Tue Oct 22 22:22:11 2024 ] Training epoch: 40
[ Tue Oct 22 22:25:57 2024 ] 	Mean training loss: 0.9141.
[ Tue Oct 22 22:25:57 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:25:57 2024 ] Eval epoch: 40
[ Tue Oct 22 22:26:14 2024 ] 	Mean test loss of 63 batches: 1.101411010064776.
[ Tue Oct 22 22:26:14 2024 ] 	Top1: 68.15%
[ Tue Oct 22 22:26:14 2024 ] 	Top5: 92.80%
[ Tue Oct 22 22:26:14 2024 ] Training epoch: 41
[ Tue Oct 22 22:30:00 2024 ] 	Mean training loss: 0.8508.
[ Tue Oct 22 22:30:00 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:30:00 2024 ] Eval epoch: 41
[ Tue Oct 22 22:30:17 2024 ] 	Mean test loss of 63 batches: 1.0833570358772127.
[ Tue Oct 22 22:30:17 2024 ] 	Top1: 69.30%
[ Tue Oct 22 22:30:17 2024 ] 	Top5: 93.25%
[ Tue Oct 22 22:30:17 2024 ] Training epoch: 42
[ Tue Oct 22 22:34:03 2024 ] 	Mean training loss: 0.8146.
[ Tue Oct 22 22:34:03 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:34:03 2024 ] Eval epoch: 42
[ Tue Oct 22 22:34:20 2024 ] 	Mean test loss of 63 batches: 1.1011465480403295.
[ Tue Oct 22 22:34:20 2024 ] 	Top1: 68.35%
[ Tue Oct 22 22:34:20 2024 ] 	Top5: 93.05%
[ Tue Oct 22 22:34:20 2024 ] Training epoch: 43
[ Tue Oct 22 22:38:06 2024 ] 	Mean training loss: 0.8101.
[ Tue Oct 22 22:38:06 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:38:06 2024 ] Eval epoch: 43
[ Tue Oct 22 22:38:24 2024 ] 	Mean test loss of 63 batches: 1.069179611783179.
[ Tue Oct 22 22:38:24 2024 ] 	Top1: 69.45%
[ Tue Oct 22 22:38:24 2024 ] 	Top5: 93.30%
[ Tue Oct 22 22:38:24 2024 ] Training epoch: 44
[ Tue Oct 22 22:42:11 2024 ] 	Mean training loss: 0.7917.
[ Tue Oct 22 22:42:11 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:42:12 2024 ] Eval epoch: 44
[ Tue Oct 22 22:42:27 2024 ] 	Mean test loss of 63 batches: 1.0646966563330755.
[ Tue Oct 22 22:42:27 2024 ] 	Top1: 69.30%
[ Tue Oct 22 22:42:28 2024 ] 	Top5: 93.40%
[ Tue Oct 22 22:42:28 2024 ] Training epoch: 45
[ Tue Oct 22 22:46:13 2024 ] 	Mean training loss: 0.7968.
[ Tue Oct 22 22:46:13 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Oct 22 22:46:13 2024 ] Eval epoch: 45
[ Tue Oct 22 22:46:30 2024 ] 	Mean test loss of 63 batches: 1.0937127492257528.
[ Tue Oct 22 22:46:30 2024 ] 	Top1: 68.60%
[ Tue Oct 22 22:46:30 2024 ] 	Top5: 93.20%
[ Tue Oct 22 22:46:30 2024 ] Training epoch: 46
[ Tue Oct 22 22:50:16 2024 ] 	Mean training loss: 0.7935.
[ Tue Oct 22 22:50:16 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Oct 22 22:50:16 2024 ] Eval epoch: 46
[ Tue Oct 22 22:50:32 2024 ] 	Mean test loss of 63 batches: 1.0953504116762252.
[ Tue Oct 22 22:50:32 2024 ] 	Top1: 68.60%
[ Tue Oct 22 22:50:32 2024 ] 	Top5: 93.10%
[ Tue Oct 22 22:50:32 2024 ] Training epoch: 47
[ Tue Oct 22 22:54:19 2024 ] 	Mean training loss: 0.7885.
[ Tue Oct 22 22:54:19 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:54:19 2024 ] Eval epoch: 47
[ Tue Oct 22 22:54:35 2024 ] 	Mean test loss of 63 batches: 1.0712533704345188.
[ Tue Oct 22 22:54:35 2024 ] 	Top1: 69.35%
[ Tue Oct 22 22:54:35 2024 ] 	Top5: 93.60%
[ Tue Oct 22 22:54:35 2024 ] Training epoch: 48
[ Tue Oct 22 22:58:22 2024 ] 	Mean training loss: 0.7803.
[ Tue Oct 22 22:58:22 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 22:58:22 2024 ] Eval epoch: 48
[ Tue Oct 22 22:58:38 2024 ] 	Mean test loss of 63 batches: 1.1049503466439625.
[ Tue Oct 22 22:58:39 2024 ] 	Top1: 68.55%
[ Tue Oct 22 22:58:39 2024 ] 	Top5: 93.00%
[ Tue Oct 22 22:58:39 2024 ] Training epoch: 49
[ Tue Oct 22 23:02:25 2024 ] 	Mean training loss: 0.7725.
[ Tue Oct 22 23:02:25 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 23:02:25 2024 ] Eval epoch: 49
[ Tue Oct 22 23:02:41 2024 ] 	Mean test loss of 63 batches: 1.0670881954923508.
[ Tue Oct 22 23:02:41 2024 ] 	Top1: 69.10%
[ Tue Oct 22 23:02:41 2024 ] 	Top5: 93.30%
[ Tue Oct 22 23:02:41 2024 ] Training epoch: 50
[ Tue Oct 22 23:06:28 2024 ] 	Mean training loss: 0.7737.
[ Tue Oct 22 23:06:28 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Oct 22 23:06:28 2024 ] Eval epoch: 50
[ Tue Oct 22 23:06:45 2024 ] 	Mean test loss of 63 batches: 1.0950097498439608.
[ Tue Oct 22 23:06:45 2024 ] 	Top1: 68.70%
[ Tue Oct 22 23:06:45 2024 ] 	Top5: 93.05%
